{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CztodpmQM11q"
      },
      "source": [
        "# Let's try HuggingFace Transformers NLP Pipelines!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dtAhiTAMmYN",
        "outputId": "153b9712-4713-4692-d4fe-f8b2c309d97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3g0V_WTMpwB",
        "outputId": "dd2567e3-c2b0-42a6-ce97-89499a3ca753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sequence': 'The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room',\n",
              " 'labels': ['aesthetics', 'texture', 'planet', 'weather'],\n",
              " 'scores': [0.7889611721038818,\n",
              "  0.16188685595989227,\n",
              "  0.030862413346767426,\n",
              "  0.018289612606167793]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "\"The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room\",\n",
        "    candidate_labels=[\"aesthetics\", \"planet\", \"weather\",\"texture\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqWM6oUbanx"
      },
      "source": [
        "Dengan menggunakan zero shot classification kita dapat mengklasifikasikan setiap kata, dengan memberikan label kadidat di bawahnya, maka dia akan memilah setiap kata dalam kalimat untuk menentukan berapa persen kalimat tersebut relate dengan label yang kita input. Kita dapat memberikan lebih dari 3 label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMxLGaXEehDl",
        "outputId": "28e5c0d3-4216-4010-cde7-89deeb8ff536"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sequence': 'The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room',\n",
              " 'labels': ['aesthetic_ambience', 'feelings_of_sadness', 'cold_weather'],\n",
              " 'scores': [0.8479993939399719, 0.114240363240242, 0.03776019066572189]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room\",\n",
        "    candidate_labels=['aesthetic_ambience', 'cold_weather','feelings_of_sadness'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcm1TX1Rgu5O"
      },
      "source": [
        "untuk pemberian label 2/lebih kata ,jika ditambahkan'_' di antara kata, persentase yang dikeluarkan lebih baik dari pada digabungkan atau hanya dipisah saja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXpng5rlgVDS",
        "outputId": "b648230a-34a5-484b-ffaf-c386be49eec2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sequence': 'The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room',\n",
              " 'labels': ['feelings_of_sadness'],\n",
              " 'scores': [0.1333836317062378]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"The mirror reflected the soft glow of the white moonlight, creating an ethereal ambiance in the dark room\",\n",
        "    candidate_labels=['feelings_of_sadness'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oirUU-hcgtpt"
      },
      "source": [
        "zero-shot-classification juga bisa hanya diberikan 1 label saja. dan tidak memberikan output 100%, output yang dikeluarkan juga tidak terlalu beda jauh dengan saat pemberian 3 label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwkn1wZaNCxn",
        "outputId": "4a79a70b-600a-4f4a-b452-78bf861a4d57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'because it\\'s hot, so today I\\'m going to go to the \\xa0Biscuit Room and take pictures of it.\"\\nHe said, \"I mean, I\\'m here for the holidays and my mom loves it.\"\\nHe said,'}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"because it's hot, so today I'm going to go to the \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5LnxGQijhxy"
      },
      "source": [
        "Dengan menggunakan text generation saya dapat membuat konten text, dimana NLP menyelesaikan perintah dengan teks yang dibuat secara otomatis. mungkin text akan diisi dengan lebih baik apabila kita memberikan clue lebih pada kalimat input kita.Walaupun terkadang jawaban yang diberikan agak aneh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drVV_RinNMws",
        "outputId": "0c7492f3-b4f9-4abb-a263-00f4ca655d4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': \"because it's hot, so today I'm going to go to the gym to get a couple of hours off, for that\"},\n",
              " {'generated_text': \"because it's hot, so today I'm going to go to the bathroom to find out what they're doing and when my\"},\n",
              " {'generated_text': \"because it's hot, so today I'm going to go to the toilet. As one of these many, many people in\"}]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"because it's hot, so today I'm going to go to the\",\n",
        "    max_length=25,\n",
        "    num_return_sequences=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx5gRbf5HJ7l"
      },
      "source": [
        "Dengan menambahkan max lenghth dan num return sequence, NLP memberikan beberapa output kata untuk mengisi text inputan, kita juga bisa mengatur panjang kalimat yang kita inginkan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv7R-U_gmGxF",
        "outputId": "d08beade-d802-4e61-d445-49f24bce7633"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'i want to eat my food!\"\\n\\n\"Yes. I love everything about it. There is no taste, smell, or anything I cannot tell'},\n",
              " {'generated_text': 'i want to eat this, I would rather eat it instead,\" she says. \"I don\\'t want to be overweight. I\\'ve been overweight in'},\n",
              " {'generated_text': 'i want to eat, then there\\'s no way anyone would ever ask for that.\\n\\n\"And we\\'re gonna have to figure out a way'},\n",
              " {'generated_text': 'i want to eat it… but i\\'m afraid you\\'re not ready, you\\'re not ready to eat this…\" Yang\\'s eyes widened and her lips'},\n",
              " {'generated_text': \"i want to eat. I don't need anything bad but I have problems eating it and I still have issues feeding it. This food has become my\"}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "generator(\"i want to eat\", max_length=30, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc20xAvrH9E-"
      },
      "source": [
        "dengan mengganti modelnya kita dapat menyesuaikan model yang akan mengeluarkan output yang sesuai dengan yang kita inginkan\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ab97He7Dd0k",
        "outputId": "14669095-5ff8-4085-b528-19d713e4a076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'score': 0.07218698412179947,\n",
              "  'token': 3571,\n",
              "  'token_str': ' exciting',\n",
              "  'sequence': 'this morning very exciting for me.'},\n",
              " {'score': 0.0661114826798439,\n",
              "  'token': 5074,\n",
              "  'token_str': ' sad',\n",
              "  'sequence': 'this morning very sad for me.'},\n",
              " {'score': 0.041860539466142654,\n",
              "  'token': 15868,\n",
              "  'token_str': ' confusing',\n",
              "  'sequence': 'this morning very confusing for me.'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"this morning very <mask> for me.\", top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrrAlZYOKj72"
      },
      "source": [
        "Dengan menggunakan fill mask saya dapat membuat konten teks dengan NLP mengisi bagian yang kosong dalam teks dengan kata-kata, kita juga diberikan beberapa keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-uxwPRKDhpB",
        "outputId": "fb812289-5927-4ca6-f2a8-71e6d145dc40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.99681234,\n",
              "  'word': 'Surgiwe',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9958063,\n",
              "  'word': 'ITEBA',\n",
              "  'start': 39,\n",
              "  'end': 44}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Surgiwe and I am student at ITEBA.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txCVANluMt6Z"
      },
      "source": [
        "Dengan menggunakan group entities saya dapat mengklasifikasi setiap kata seperti nama orang, lokasi, atau nama organisasinya, output nya juga menghitung urutan kata tersebut ke berapa, dan terakhir berapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SbkDlwfDlF5",
        "outputId": "f0be97ad-94f4-4939-87ed-96878b12fd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: juga meningkatkan kreatifitas\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"lego dapat membuat kita untuk berkresi di waktu kosong, tidak hanya itu lego juga meningkatkan kreatifitas.\"\n",
        "question = \"apa saja fungsi lego?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzegOXIgMvD2"
      },
      "source": [
        "Dengan menggunakan question answering NLP dapat menjawab pertanyaan yang diberikan berdasarkan konteks yang sudah kita beri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y1wD47GplfT",
        "outputId": "2ac17699-053f-4a9d-aaae-cddca7553a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: South Korean\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"NCT is a South Korean boy band formed and managed by SM Entertainment. Introduced in January 2016, the group consists of 25 members divided into six different sub-units: NCT U, NCT 127, NCT Dream, WayV, NCT DoJaeJung, and NCT Wish.\"\n",
        "question = \"where are from NCT?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "158wcPBrMvsc"
      },
      "source": [
        "NLP dapat mengekstrak jawaban dari kalimat atau konteks yang kita beri, walaupun di konteks tidak ada kata kata from hanya ada kalimat NCT adalah boyband korea selatan, namun NLP bisa menangkap bahwa berarti itu adalah asal boyband tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3IZcIeAE41r",
        "outputId": "a36bd305-c8fe-46be-a2a1-2a3de7b2de07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9670995473861694}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"i want to eat noodle but i want eat meat ball too\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHMkdAMKMwaH"
      },
      "source": [
        "dengan menggunakan sentiment analysis NLP dapat mengklasifikasikan seluruh kalimat, apakah kalimat tersebut positive atau negative, namun terkadang output yang dikeluarkan tidak sesuai dengan yang diharapkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSjHIImDptH",
        "outputId": "084f92f5-3fec-4602-f24c-53974705472d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Your min_length=56 must be inferior than your max_length=30.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' Amy Poehler, Phyllis Smith, Lewis Black, Diane Lane, and Kyle MacLachlan reprise their roles from the'}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Inside Out 2 is a 2024 American animated coming-of-age film produced by Pixar Animation Studios for Walt Disney Pictures. The sequel to Inside Out (2015), it was directed by\n",
        "    Kelsey Mann (in his feature directorial debut) and produced by Mark Nielsen, from a screenplay written by Meg LeFauve and Dave Holstein, and a story conceived by Mann and\n",
        "    LeFauve. Amy Poehler, Phyllis Smith, Lewis Black, Diane Lane, and Kyle MacLachlan reprise their roles from the first film, with Maya Hawke, Kensington Tallman, Liza Lapira\n",
        "    (replacing Mindy Kaling), Tony Hale (replacing Bill Hader), Ayo Edebiri, Lilimar, Grace Lu, Sumayyah Nuriddin-Green, Adèle Exarchopoulos, and Paul Walter Hauser joining the\n",
        "    cast. The film tells the story of Riley's emotions as they find themselves joined by new emotions that want to take over Riley's head.\n",
        "\"\"\",max_length=30\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPNoyY1jMyIB"
      },
      "source": [
        "Dengan menggunakan summarization NLP dapat membuat kalimat baru dari teks input dengan meringkat teks input yang diberikan, kita juga dapat mengatur berapa kata yang akan dibuat sebagai input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxr6a3YYDtmL",
        "outputId": "3f6afab5-70ae-45cd-8128-05f363505107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bonjour, je m'appelle Surgiwe. J'adore manger épicé et voyager.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-id-fr\")\n",
        "\n",
        "text_to_translate = \"Halo, nama saya surgiwe, saya suka makanan pedas dan travelling\"\n",
        "result = translator(text_to_translate)\n",
        "\n",
        "print(result[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ2DD_XpY6PC"
      },
      "source": [
        "dengan menggunakan translation, NLP dapat menerjemah bahasa input ke bahasa lain, dengan cara kita mengganti modelnya."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
